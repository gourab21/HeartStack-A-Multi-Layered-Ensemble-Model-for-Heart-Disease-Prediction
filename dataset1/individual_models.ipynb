{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"./heart_statlog_cleveland_hungary_final.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.8403361344537815,\n",
       " 'Random Forest': 0.9243697478991597,\n",
       " 'Gradient Boosting': 0.9033613445378151,\n",
       " 'Support Vector Machine': 0.8781512605042017,\n",
       " 'K-Nearest Neighbors': 0.8361344537815126,\n",
       " 'Decision Tree': 0.8865546218487395,\n",
       " 'Naive Bayes': 0.8403361344537815}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Rename columns for consistency\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=[\"target\"])\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "accuracy_results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_results[name] = accuracy\n",
    "\n",
    "# Display results\n",
    "accuracy_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.8403361344537815,\n",
       " 'Random Forest': 0.9243697478991597,\n",
       " 'Gradient Boosting': 0.9033613445378151,\n",
       " 'Support Vector Machine': 0.8781512605042017,\n",
       " 'K-Nearest Neighbors': 0.8361344537815126,\n",
       " 'Decision Tree': 0.8865546218487395,\n",
       " 'Naive Bayes': 0.8403361344537815,\n",
       " 'XGBoost': 0.9369747899159664,\n",
       " 'AdaBoost': 0.8781512605042017,\n",
       " 'Extra Trees': 0.9159663865546218}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier\n",
    "\n",
    "# Additional models\n",
    "extra_models = {\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Extra Trees\": ExtraTreesClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate additional models\n",
    "for name, model in extra_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_results[name] = accuracy\n",
    "\n",
    "# Display updated results\n",
    "accuracy_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: 0.9369747899159664\n",
      "Random Forest: 0.9243697478991597\n",
      "Extra Trees: 0.9159663865546218\n",
      "Gradient Boosting: 0.9033613445378151\n",
      "Decision Tree: 0.8865546218487395\n",
      "Support Vector Machine: 0.8781512605042017\n",
      "AdaBoost: 0.8781512605042017\n",
      "Logistic Regression: 0.8403361344537815\n",
      "Naive Bayes: 0.8403361344537815\n",
      "K-Nearest Neighbors: 0.8361344537815126\n"
     ]
    }
   ],
   "source": [
    "# Sort accuracy results in descending order\n",
    "sorted_results = sorted(accuracy_results.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Print results line by line\n",
    "for name, accuracy in sorted_results:\n",
    "    print(f\"{name}: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees: 0.926890756302521\n",
      "Random Forest: 0.9241596638655463\n",
      "XGBoost: 0.9235294117647058\n",
      "Gradient Boosting: 0.8918067226890756\n",
      "Decision Tree: 0.8779411764705882\n",
      "Support Vector Machine: 0.8686974789915967\n",
      "AdaBoost: 0.8563025210084035\n",
      "K-Nearest Neighbors: 0.8556722689075631\n",
      "Naive Bayes: 0.8378151260504202\n",
      "Logistic Regression: 0.8262605042016806\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of iterations\n",
    "num_iterations = 20\n",
    "\n",
    "# Dictionary to store cumulative accuracy\n",
    "average_accuracy_results = {name: [] for name in models.keys()}\n",
    "average_accuracy_results.update({name: [] for name in extra_models.keys()})\n",
    "\n",
    "# Run the models multiple times\n",
    "for _ in range(num_iterations):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, stratify=y)\n",
    "\n",
    "    # Standardize the features\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Train and evaluate models\n",
    "    for name, model in {**models, **extra_models}.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        average_accuracy_results[name].append(accuracy)\n",
    "\n",
    "# Compute the average accuracy\n",
    "final_avg_results = {name: np.mean(acc_list) for name, acc_list in average_accuracy_results.items()}\n",
    "\n",
    "# Sort and display results\n",
    "sorted_avg_results = sorted(final_avg_results.items(), key=lambda item: item[1], reverse=True)\n",
    "for name, avg_acc in sorted_avg_results:\n",
    "    print(f\"{name}: {avg_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
